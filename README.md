# PrecisionFDA_App-a-thon

## Submission Information
This App-a-thon will consist of two submission tracks, beginner and advanced. Each submission must consist of at least one complete BCO, which will be judged, in part, on adherence to the [BioCompute specification](https://github.com/biocompute-objects/BCO_Specification/tree/1.3.0)
Advanced track details
Submissions for this track will be an application uploaded to the precisionFDA site ( or code for an application)  supporting the creation and display of a BCO, and the ability to check conformance against the BioCompute specification, as well as a user manual. It is acceptable to build from existing tools if proper attribution is given. Advanced track participants will receive a pre-curated BCO and a randomly sourced BCO submission from the beginner track as input. Reviewers will evaluate the tool based on ease of use, aesthetic appeal, ability of the tool to correctly spot errors in specification compliance, and the quality of the user manual (README).

## Advanced track submission details
A valid submission to the advanced track requires:
- The ability of the tool to do the following:
- Create a BCO
- Check a BCO for conformance
- Display a BCO
The application can be directly uploaded on the precisionFDA website using the following resources:
•	https://youtu.be/f-DBLB2v1sM  (how to create an app)
•	https://youtu.be/4-voYR-q-cw (Application import)
•	https://precision.fda.gov/docs/creating_apps
Advanced track evaluation details
Experts will utilize the following criteria to evaluate coding application submissions:
•	Ease of use 
•	Aesthetic appeal
•	Can handle user input and make a BCO
•	Can display a BCO (points awarded for the creativity of the display)
•	Can check conformance of a BCO for both pre-curated BCO and a randomly sourced BCO submission from the beginner track (points awarded for accurately identifying deviations from the specification with no errors)
•	If integrated in a platform, is able to reproduce native pipelines
•	A User manual/README sufficient to execute the program

### Additional Notes

For submissions that are integrated into a platform (e.g. Galaxy), a large amount of information can be automatically captured from a workflow created on that platform without any manual input from the user. It is up to the participant to determine how much information is automated on their own platform. However, some fields will require manual input (e.g., the usability domain containing the purpose of the experiment). Points will be awarded for additional functionality (e.g., comparing a specific output file to the Error Domain).

